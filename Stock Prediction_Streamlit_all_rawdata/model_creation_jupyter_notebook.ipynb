{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ebf411-4be8-43aa-9d1f-e2cc8c2d6a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.04604257, 0.04506337, 0.04206481, 0.04532757, 0.04993718,\n",
      "       0.05061338, 0.05262905, 0.05861508, 0.06374571, 0.06062151,\n",
      "       0.05678418, 0.05542438, 0.05422348, 0.05405535, 0.05493109,\n",
      "       0.05605439, 0.05507704, 0.05507704, 0.05535787, 0.05403133,\n",
      "       0.0509367 , 0.04675018, 0.04971548, 0.0508591 , 0.04749104,\n",
      "       0.0460943 , 0.0460204 , 0.05012748, 0.04691276, 0.04859032,\n",
      "       0.04577467, 0.04583749, 0.04617189, 0.04676311, 0.05363411,\n",
      "       0.06106308, 0.06908694, 0.06704356, 0.07483464, 0.07684847,\n",
      "       0.07368178, 0.06661125, 0.07128552, 0.06489672, 0.05661234,\n",
      "       0.05216347, 0.05250711, 0.05286923, 0.04953627, 0.04808041,\n",
      "       0.05386321, 0.05936703, 0.06725419, 0.06853453, 0.06853453,\n",
      "       0.06853453, 0.06529579, 0.06106123, 0.05835459, 0.05734212])]\n",
      "\n",
      "[0.053345898619059834]\n",
      "[array([0.04604257, 0.04506337, 0.04206481, 0.04532757, 0.04993718,\n",
      "       0.05061338, 0.05262905, 0.05861508, 0.06374571, 0.06062151,\n",
      "       0.05678418, 0.05542438, 0.05422348, 0.05405535, 0.05493109,\n",
      "       0.05605439, 0.05507704, 0.05507704, 0.05535787, 0.05403133,\n",
      "       0.0509367 , 0.04675018, 0.04971548, 0.0508591 , 0.04749104,\n",
      "       0.0460943 , 0.0460204 , 0.05012748, 0.04691276, 0.04859032,\n",
      "       0.04577467, 0.04583749, 0.04617189, 0.04676311, 0.05363411,\n",
      "       0.06106308, 0.06908694, 0.06704356, 0.07483464, 0.07684847,\n",
      "       0.07368178, 0.06661125, 0.07128552, 0.06489672, 0.05661234,\n",
      "       0.05216347, 0.05250711, 0.05286923, 0.04953627, 0.04808041,\n",
      "       0.05386321, 0.05936703, 0.06725419, 0.06853453, 0.06853453,\n",
      "       0.06853453, 0.06529579, 0.06106123, 0.05835459, 0.05734212]), array([0.04506337, 0.04206481, 0.04532757, 0.04993718, 0.05061338,\n",
      "       0.05262905, 0.05861508, 0.06374571, 0.06062151, 0.05678418,\n",
      "       0.05542438, 0.05422348, 0.05405535, 0.05493109, 0.05605439,\n",
      "       0.05507704, 0.05507704, 0.05535787, 0.05403133, 0.0509367 ,\n",
      "       0.04675018, 0.04971548, 0.0508591 , 0.04749104, 0.0460943 ,\n",
      "       0.0460204 , 0.05012748, 0.04691276, 0.04859032, 0.04577467,\n",
      "       0.04583749, 0.04617189, 0.04676311, 0.05363411, 0.06106308,\n",
      "       0.06908694, 0.06704356, 0.07483464, 0.07684847, 0.07368178,\n",
      "       0.06661125, 0.07128552, 0.06489672, 0.05661234, 0.05216347,\n",
      "       0.05250711, 0.05286923, 0.04953627, 0.04808041, 0.05386321,\n",
      "       0.05936703, 0.06725419, 0.06853453, 0.06853453, 0.06853453,\n",
      "       0.06529579, 0.06106123, 0.05835459, 0.05734212, 0.0533459 ])]\n",
      "\n",
      "[0.053345898619059834, 0.053458595911102844]\n",
      "[array([0.04604257, 0.04506337, 0.04206481, 0.04532757, 0.04993718,\n",
      "       0.05061338, 0.05262905, 0.05861508, 0.06374571, 0.06062151,\n",
      "       0.05678418, 0.05542438, 0.05422348, 0.05405535, 0.05493109,\n",
      "       0.05605439, 0.05507704, 0.05507704, 0.05535787, 0.05403133,\n",
      "       0.0509367 , 0.04675018, 0.04971548, 0.0508591 , 0.04749104,\n",
      "       0.0460943 , 0.0460204 , 0.05012748, 0.04691276, 0.04859032,\n",
      "       0.04577467, 0.04583749, 0.04617189, 0.04676311, 0.05363411,\n",
      "       0.06106308, 0.06908694, 0.06704356, 0.07483464, 0.07684847,\n",
      "       0.07368178, 0.06661125, 0.07128552, 0.06489672, 0.05661234,\n",
      "       0.05216347, 0.05250711, 0.05286923, 0.04953627, 0.04808041,\n",
      "       0.05386321, 0.05936703, 0.06725419, 0.06853453, 0.06853453,\n",
      "       0.06853453, 0.06529579, 0.06106123, 0.05835459, 0.05734212]), array([0.04506337, 0.04206481, 0.04532757, 0.04993718, 0.05061338,\n",
      "       0.05262905, 0.05861508, 0.06374571, 0.06062151, 0.05678418,\n",
      "       0.05542438, 0.05422348, 0.05405535, 0.05493109, 0.05605439,\n",
      "       0.05507704, 0.05507704, 0.05535787, 0.05403133, 0.0509367 ,\n",
      "       0.04675018, 0.04971548, 0.0508591 , 0.04749104, 0.0460943 ,\n",
      "       0.0460204 , 0.05012748, 0.04691276, 0.04859032, 0.04577467,\n",
      "       0.04583749, 0.04617189, 0.04676311, 0.05363411, 0.06106308,\n",
      "       0.06908694, 0.06704356, 0.07483464, 0.07684847, 0.07368178,\n",
      "       0.06661125, 0.07128552, 0.06489672, 0.05661234, 0.05216347,\n",
      "       0.05250711, 0.05286923, 0.04953627, 0.04808041, 0.05386321,\n",
      "       0.05936703, 0.06725419, 0.06853453, 0.06853453, 0.06853453,\n",
      "       0.06529579, 0.06106123, 0.05835459, 0.05734212, 0.0533459 ]), array([0.04206481, 0.04532757, 0.04993718, 0.05061338, 0.05262905,\n",
      "       0.05861508, 0.06374571, 0.06062151, 0.05678418, 0.05542438,\n",
      "       0.05422348, 0.05405535, 0.05493109, 0.05605439, 0.05507704,\n",
      "       0.05507704, 0.05535787, 0.05403133, 0.0509367 , 0.04675018,\n",
      "       0.04971548, 0.0508591 , 0.04749104, 0.0460943 , 0.0460204 ,\n",
      "       0.05012748, 0.04691276, 0.04859032, 0.04577467, 0.04583749,\n",
      "       0.04617189, 0.04676311, 0.05363411, 0.06106308, 0.06908694,\n",
      "       0.06704356, 0.07483464, 0.07684847, 0.07368178, 0.06661125,\n",
      "       0.07128552, 0.06489672, 0.05661234, 0.05216347, 0.05250711,\n",
      "       0.05286923, 0.04953627, 0.04808041, 0.05386321, 0.05936703,\n",
      "       0.06725419, 0.06853453, 0.06853453, 0.06853453, 0.06529579,\n",
      "       0.06106123, 0.05835459, 0.05734212, 0.0533459 , 0.0534586 ])]\n",
      "\n",
      "[0.053345898619059834, 0.053458595911102844, 0.052420278795159606]\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 60, 50)            10400     \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "4400/4400 [==============================] - 82s 18ms/step - loss: 2.2611e-04\n",
      "Epoch 2/10\n",
      "4400/4400 [==============================] - 82s 19ms/step - loss: 8.4275e-05\n",
      "Epoch 3/10\n",
      "4400/4400 [==============================] - 82s 19ms/step - loss: 5.1900e-05\n",
      "Epoch 4/10\n",
      "4400/4400 [==============================] - 82s 19ms/step - loss: 4.0394e-05\n",
      "Epoch 5/10\n",
      "4400/4400 [==============================] - 82s 19ms/step - loss: 3.3987e-05\n",
      "Epoch 6/10\n",
      "4400/4400 [==============================] - 82s 19ms/step - loss: 3.2563e-05\n",
      "Epoch 7/10\n",
      "4400/4400 [==============================] - 82s 19ms/step - loss: 3.6364e-05\n",
      "Epoch 8/10\n",
      "4400/4400 [==============================] - 82s 19ms/step - loss: 2.8812e-05\n",
      "Epoch 9/10\n",
      "4400/4400 [==============================] - 82s 19ms/step - loss: 2.8836e-05\n",
      "Epoch 10/10\n",
      "4400/4400 [==============================] - 82s 19ms/step - loss: 2.3966e-05\n",
      "Root mean square error in predicted vs actual values  40.17667299883584\n",
      "stock name  HINDUNILVR.NS\n",
      "[array([0.02171777, 0.02985332, 0.03257666, 0.03159419, 0.03249048,\n",
      "       0.03162866, 0.0280435 , 0.02326904, 0.02504438, 0.02630264,\n",
      "       0.0249582 , 0.0240102 , 0.02318286, 0.02316562, 0.02311392,\n",
      "       0.02013203, 0.01942534, 0.0189772 , 0.01501284, 0.01451299,\n",
      "       0.01685713, 0.01685713, 0.01827051, 0.01658135, 0.01596084,\n",
      "       0.01492666, 0.01492666, 0.01216885, 0.01142768, 0.01182412,\n",
      "       0.01213437, 0.01244463, 0.01311684, 0.01296172, 0.01496113,\n",
      "       0.01601255, 0.01596084, 0.01540928, 0.01511626, 0.01394419,\n",
      "       0.01339263, 0.01235845, 0.01222056, 0.01177241, 0.01165176,\n",
      "       0.01160005, 0.01184136, 0.01184136, 0.01280659, 0.01220332,\n",
      "       0.01284106, 0.01375459, 0.0126687 , 0.01287554, 0.01182412,\n",
      "       0.01168623, 0.01051416, 0.00873882, 0.00873882, 0.00835962])]\n",
      "\n",
      "[0.007480566143156071]\n",
      "[array([0.02171777, 0.02985332, 0.03257666, 0.03159419, 0.03249048,\n",
      "       0.03162866, 0.0280435 , 0.02326904, 0.02504438, 0.02630264,\n",
      "       0.0249582 , 0.0240102 , 0.02318286, 0.02316562, 0.02311392,\n",
      "       0.02013203, 0.01942534, 0.0189772 , 0.01501284, 0.01451299,\n",
      "       0.01685713, 0.01685713, 0.01827051, 0.01658135, 0.01596084,\n",
      "       0.01492666, 0.01492666, 0.01216885, 0.01142768, 0.01182412,\n",
      "       0.01213437, 0.01244463, 0.01311684, 0.01296172, 0.01496113,\n",
      "       0.01601255, 0.01596084, 0.01540928, 0.01511626, 0.01394419,\n",
      "       0.01339263, 0.01235845, 0.01222056, 0.01177241, 0.01165176,\n",
      "       0.01160005, 0.01184136, 0.01184136, 0.01280659, 0.01220332,\n",
      "       0.01284106, 0.01375459, 0.0126687 , 0.01287554, 0.01182412,\n",
      "       0.01168623, 0.01051416, 0.00873882, 0.00873882, 0.00835962]), array([0.02985332, 0.03257666, 0.03159419, 0.03249048, 0.03162866,\n",
      "       0.0280435 , 0.02326904, 0.02504438, 0.02630264, 0.0249582 ,\n",
      "       0.0240102 , 0.02318286, 0.02316562, 0.02311392, 0.02013203,\n",
      "       0.01942534, 0.0189772 , 0.01501284, 0.01451299, 0.01685713,\n",
      "       0.01685713, 0.01827051, 0.01658135, 0.01596084, 0.01492666,\n",
      "       0.01492666, 0.01216885, 0.01142768, 0.01182412, 0.01213437,\n",
      "       0.01244463, 0.01311684, 0.01296172, 0.01496113, 0.01601255,\n",
      "       0.01596084, 0.01540928, 0.01511626, 0.01394419, 0.01339263,\n",
      "       0.01235845, 0.01222056, 0.01177241, 0.01165176, 0.01160005,\n",
      "       0.01184136, 0.01184136, 0.01280659, 0.01220332, 0.01284106,\n",
      "       0.01375459, 0.0126687 , 0.01287554, 0.01182412, 0.01168623,\n",
      "       0.01051416, 0.00873882, 0.00873882, 0.00835962, 0.00748057])]\n",
      "\n",
      "[0.007480566143156071, 0.00592929737851872]\n",
      "[array([0.02171777, 0.02985332, 0.03257666, 0.03159419, 0.03249048,\n",
      "       0.03162866, 0.0280435 , 0.02326904, 0.02504438, 0.02630264,\n",
      "       0.0249582 , 0.0240102 , 0.02318286, 0.02316562, 0.02311392,\n",
      "       0.02013203, 0.01942534, 0.0189772 , 0.01501284, 0.01451299,\n",
      "       0.01685713, 0.01685713, 0.01827051, 0.01658135, 0.01596084,\n",
      "       0.01492666, 0.01492666, 0.01216885, 0.01142768, 0.01182412,\n",
      "       0.01213437, 0.01244463, 0.01311684, 0.01296172, 0.01496113,\n",
      "       0.01601255, 0.01596084, 0.01540928, 0.01511626, 0.01394419,\n",
      "       0.01339263, 0.01235845, 0.01222056, 0.01177241, 0.01165176,\n",
      "       0.01160005, 0.01184136, 0.01184136, 0.01280659, 0.01220332,\n",
      "       0.01284106, 0.01375459, 0.0126687 , 0.01287554, 0.01182412,\n",
      "       0.01168623, 0.01051416, 0.00873882, 0.00873882, 0.00835962]), array([0.02985332, 0.03257666, 0.03159419, 0.03249048, 0.03162866,\n",
      "       0.0280435 , 0.02326904, 0.02504438, 0.02630264, 0.0249582 ,\n",
      "       0.0240102 , 0.02318286, 0.02316562, 0.02311392, 0.02013203,\n",
      "       0.01942534, 0.0189772 , 0.01501284, 0.01451299, 0.01685713,\n",
      "       0.01685713, 0.01827051, 0.01658135, 0.01596084, 0.01492666,\n",
      "       0.01492666, 0.01216885, 0.01142768, 0.01182412, 0.01213437,\n",
      "       0.01244463, 0.01311684, 0.01296172, 0.01496113, 0.01601255,\n",
      "       0.01596084, 0.01540928, 0.01511626, 0.01394419, 0.01339263,\n",
      "       0.01235845, 0.01222056, 0.01177241, 0.01165176, 0.01160005,\n",
      "       0.01184136, 0.01184136, 0.01280659, 0.01220332, 0.01284106,\n",
      "       0.01375459, 0.0126687 , 0.01287554, 0.01182412, 0.01168623,\n",
      "       0.01051416, 0.00873882, 0.00873882, 0.00835962, 0.00748057]), array([0.03257666, 0.03159419, 0.03249048, 0.03162866, 0.0280435 ,\n",
      "       0.02326904, 0.02504438, 0.02630264, 0.0249582 , 0.0240102 ,\n",
      "       0.02318286, 0.02316562, 0.02311392, 0.02013203, 0.01942534,\n",
      "       0.0189772 , 0.01501284, 0.01451299, 0.01685713, 0.01685713,\n",
      "       0.01827051, 0.01658135, 0.01596084, 0.01492666, 0.01492666,\n",
      "       0.01216885, 0.01142768, 0.01182412, 0.01213437, 0.01244463,\n",
      "       0.01311684, 0.01296172, 0.01496113, 0.01601255, 0.01596084,\n",
      "       0.01540928, 0.01511626, 0.01394419, 0.01339263, 0.01235845,\n",
      "       0.01222056, 0.01177241, 0.01165176, 0.01160005, 0.01184136,\n",
      "       0.01184136, 0.01280659, 0.01220332, 0.01284106, 0.01375459,\n",
      "       0.0126687 , 0.01287554, 0.01182412, 0.01168623, 0.01051416,\n",
      "       0.00873882, 0.00873882, 0.00835962, 0.00748057, 0.0059293 ])]\n",
      "\n",
      "[0.007480566143156071, 0.00592929737851872, 0.004739989901017084]\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 60, 50)            10400     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "3567/3567 [==============================] - 69s 19ms/step - loss: 4.2246e-04\n",
      "Epoch 2/10\n",
      "3567/3567 [==============================] - 68s 19ms/step - loss: 1.4864e-04\n",
      "Epoch 3/10\n",
      "3567/3567 [==============================] - 68s 19ms/step - loss: 1.5287e-04\n",
      "Epoch 4/10\n",
      "3567/3567 [==============================] - 68s 19ms/step - loss: 9.3290e-05\n",
      "Epoch 5/10\n",
      "3567/3567 [==============================] - 78s 22ms/step - loss: 8.6630e-05\n",
      "Epoch 6/10\n",
      "3567/3567 [==============================] - 69s 19ms/step - loss: 7.4762e-05\n",
      "Epoch 7/10\n",
      "3567/3567 [==============================] - 71s 20ms/step - loss: 7.1606e-05\n",
      "Epoch 8/10\n",
      "3567/3567 [==============================] - 69s 19ms/step - loss: 6.2065e-05\n",
      "Epoch 9/10\n",
      "3567/3567 [==============================] - 72s 20ms/step - loss: 5.8504e-05\n",
      "Epoch 10/10\n",
      "3567/3567 [==============================] - 80s 22ms/step - loss: 5.5475e-05\n",
      "Root mean square error in predicted vs actual values  7.8115251553769145\n",
      "stock name  IGL.NS\n",
      "[array([0.78217811, 0.84158429, 0.77227727, 0.67326735, 0.89108924,\n",
      "       0.96039626, 0.9702971 , 0.88118803, 0.90099008, 0.90099008,\n",
      "       0.90099008, 0.9702971 , 1.        , 0.88118803, 0.95049504,\n",
      "       0.89108924, 0.82178223, 0.81188139, 0.80198017, 0.81188139,\n",
      "       0.75247521, 1.        , 0.95049504, 0.92079214, 0.90099008,\n",
      "       0.81188139, 0.79207933, 0.81188139, 0.79207933, 0.79207933,\n",
      "       0.75247521, 0.73267315, 0.65346529, 0.63366324, 0.61386155,\n",
      "       0.60396034, 0.58415828, 0.51485164, 0.41584172, 0.4356434 ,\n",
      "       0.41584172, 0.4059405 , 0.39603966, 0.32673265, 0.22772273,\n",
      "       0.25742563, 0.21782189, 0.21782189, 0.        , 0.11881197,\n",
      "       0.04950496, 0.17821777, 0.0594058 , 0.07920786, 0.03960374,\n",
      "       0.04950496, 0.0297029 , 0.06930702, 0.0594058 , 0.0594058 ])]\n",
      "\n",
      "[0.08910869773769559]\n",
      "[array([0.78217811, 0.84158429, 0.77227727, 0.67326735, 0.89108924,\n",
      "       0.96039626, 0.9702971 , 0.88118803, 0.90099008, 0.90099008,\n",
      "       0.90099008, 0.9702971 , 1.        , 0.88118803, 0.95049504,\n",
      "       0.89108924, 0.82178223, 0.81188139, 0.80198017, 0.81188139,\n",
      "       0.75247521, 1.        , 0.95049504, 0.92079214, 0.90099008,\n",
      "       0.81188139, 0.79207933, 0.81188139, 0.79207933, 0.79207933,\n",
      "       0.75247521, 0.73267315, 0.65346529, 0.63366324, 0.61386155,\n",
      "       0.60396034, 0.58415828, 0.51485164, 0.41584172, 0.4356434 ,\n",
      "       0.41584172, 0.4059405 , 0.39603966, 0.32673265, 0.22772273,\n",
      "       0.25742563, 0.21782189, 0.21782189, 0.        , 0.11881197,\n",
      "       0.04950496, 0.17821777, 0.0594058 , 0.07920786, 0.03960374,\n",
      "       0.04950496, 0.0297029 , 0.06930702, 0.0594058 , 0.0594058 ]), array([0.84158429, 0.77227727, 0.67326735, 0.89108924, 0.96039626,\n",
      "       0.9702971 , 0.88118803, 0.90099008, 0.90099008, 0.90099008,\n",
      "       0.9702971 , 1.        , 0.88118803, 0.95049504, 0.89108924,\n",
      "       0.82178223, 0.81188139, 0.80198017, 0.81188139, 0.75247521,\n",
      "       1.        , 0.95049504, 0.92079214, 0.90099008, 0.81188139,\n",
      "       0.79207933, 0.81188139, 0.79207933, 0.79207933, 0.75247521,\n",
      "       0.73267315, 0.65346529, 0.63366324, 0.61386155, 0.60396034,\n",
      "       0.58415828, 0.51485164, 0.41584172, 0.4356434 , 0.41584172,\n",
      "       0.4059405 , 0.39603966, 0.32673265, 0.22772273, 0.25742563,\n",
      "       0.21782189, 0.21782189, 0.        , 0.11881197, 0.04950496,\n",
      "       0.17821777, 0.0594058 , 0.07920786, 0.03960374, 0.04950496,\n",
      "       0.0297029 , 0.06930702, 0.0594058 , 0.0594058 , 0.0891087 ])]\n",
      "\n",
      "[0.08910869773769559, 0.039603739763578893]\n",
      "[array([0.78217811, 0.84158429, 0.77227727, 0.67326735, 0.89108924,\n",
      "       0.96039626, 0.9702971 , 0.88118803, 0.90099008, 0.90099008,\n",
      "       0.90099008, 0.9702971 , 1.        , 0.88118803, 0.95049504,\n",
      "       0.89108924, 0.82178223, 0.81188139, 0.80198017, 0.81188139,\n",
      "       0.75247521, 1.        , 0.95049504, 0.92079214, 0.90099008,\n",
      "       0.81188139, 0.79207933, 0.81188139, 0.79207933, 0.79207933,\n",
      "       0.75247521, 0.73267315, 0.65346529, 0.63366324, 0.61386155,\n",
      "       0.60396034, 0.58415828, 0.51485164, 0.41584172, 0.4356434 ,\n",
      "       0.41584172, 0.4059405 , 0.39603966, 0.32673265, 0.22772273,\n",
      "       0.25742563, 0.21782189, 0.21782189, 0.        , 0.11881197,\n",
      "       0.04950496, 0.17821777, 0.0594058 , 0.07920786, 0.03960374,\n",
      "       0.04950496, 0.0297029 , 0.06930702, 0.0594058 , 0.0594058 ]), array([0.84158429, 0.77227727, 0.67326735, 0.89108924, 0.96039626,\n",
      "       0.9702971 , 0.88118803, 0.90099008, 0.90099008, 0.90099008,\n",
      "       0.9702971 , 1.        , 0.88118803, 0.95049504, 0.89108924,\n",
      "       0.82178223, 0.81188139, 0.80198017, 0.81188139, 0.75247521,\n",
      "       1.        , 0.95049504, 0.92079214, 0.90099008, 0.81188139,\n",
      "       0.79207933, 0.81188139, 0.79207933, 0.79207933, 0.75247521,\n",
      "       0.73267315, 0.65346529, 0.63366324, 0.61386155, 0.60396034,\n",
      "       0.58415828, 0.51485164, 0.41584172, 0.4356434 , 0.41584172,\n",
      "       0.4059405 , 0.39603966, 0.32673265, 0.22772273, 0.25742563,\n",
      "       0.21782189, 0.21782189, 0.        , 0.11881197, 0.04950496,\n",
      "       0.17821777, 0.0594058 , 0.07920786, 0.03960374, 0.04950496,\n",
      "       0.0297029 , 0.06930702, 0.0594058 , 0.0594058 , 0.0891087 ]), array([0.77227727, 0.67326735, 0.89108924, 0.96039626, 0.9702971 ,\n",
      "       0.88118803, 0.90099008, 0.90099008, 0.90099008, 0.9702971 ,\n",
      "       1.        , 0.88118803, 0.95049504, 0.89108924, 0.82178223,\n",
      "       0.81188139, 0.80198017, 0.81188139, 0.75247521, 1.        ,\n",
      "       0.95049504, 0.92079214, 0.90099008, 0.81188139, 0.79207933,\n",
      "       0.81188139, 0.79207933, 0.79207933, 0.75247521, 0.73267315,\n",
      "       0.65346529, 0.63366324, 0.61386155, 0.60396034, 0.58415828,\n",
      "       0.51485164, 0.41584172, 0.4356434 , 0.41584172, 0.4059405 ,\n",
      "       0.39603966, 0.32673265, 0.22772273, 0.25742563, 0.21782189,\n",
      "       0.21782189, 0.        , 0.11881197, 0.04950496, 0.17821777,\n",
      "       0.0594058 , 0.07920786, 0.03960374, 0.04950496, 0.0297029 ,\n",
      "       0.06930702, 0.0594058 , 0.0594058 , 0.0891087 , 0.03960374])]\n",
      "\n",
      "[0.08910869773769559, 0.039603739763578893, 0.019802058728217276]\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 60, 50)            10400     \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 6s 20ms/step - loss: 0.0279\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0151\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 5s 28ms/step - loss: 0.0107\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.0090\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.0090\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.0098\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0082\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0081\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.0087\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0081\n",
      "Root mean square error in predicted vs actual values  0.47311379114786783\n",
      "stock name  IRFC.NS\n",
      "[array([0.00000000e+00, 0.00000000e+00, 1.77984126e-04, 8.89920632e-05,\n",
      "       1.15689343e-03, 4.18261169e-03, 7.92026477e-03, 9.07715650e-03,\n",
      "       9.52211512e-03, 8.98816613e-03, 8.98816613e-03, 1.14799337e-02,\n",
      "       1.09459813e-02, 1.09459813e-02, 1.15689241e-02, 1.29037999e-02,\n",
      "       1.98451537e-02, 1.81543130e-02, 1.88662461e-02, 1.83322971e-02,\n",
      "       1.71754020e-02, 1.71754020e-02, 1.33487586e-02, 1.49506089e-02,\n",
      "       1.58405261e-02, 1.51285930e-02, 1.36157330e-02, 1.53955675e-02,\n",
      "       1.60185103e-02, 1.71754020e-02, 1.67304434e-02, 1.64634689e-02,\n",
      "       1.41496854e-02, 1.52175868e-02, 1.52175868e-02, 1.14799337e-02,\n",
      "       9.70009924e-03, 1.28148096e-02, 1.58405261e-02, 1.59295199e-02,\n",
      "       1.60185103e-02, 1.60185103e-02, 1.61075040e-02, 1.59295199e-02,\n",
      "       1.59295199e-02, 1.53065772e-02, 1.46836344e-02, 1.60185103e-02,\n",
      "       1.60185103e-02, 1.48616185e-02, 1.47726282e-02, 1.47726282e-02,\n",
      "       1.43276696e-02, 1.40606917e-02, 1.40606917e-02, 1.33487586e-02,\n",
      "       1.29037999e-02, 1.24588413e-02, 1.18358986e-02, 1.14799337e-02])]\n",
      "\n",
      "[0.011746908208576379]\n",
      "[array([0.00000000e+00, 0.00000000e+00, 1.77984126e-04, 8.89920632e-05,\n",
      "       1.15689343e-03, 4.18261169e-03, 7.92026477e-03, 9.07715650e-03,\n",
      "       9.52211512e-03, 8.98816613e-03, 8.98816613e-03, 1.14799337e-02,\n",
      "       1.09459813e-02, 1.09459813e-02, 1.15689241e-02, 1.29037999e-02,\n",
      "       1.98451537e-02, 1.81543130e-02, 1.88662461e-02, 1.83322971e-02,\n",
      "       1.71754020e-02, 1.71754020e-02, 1.33487586e-02, 1.49506089e-02,\n",
      "       1.58405261e-02, 1.51285930e-02, 1.36157330e-02, 1.53955675e-02,\n",
      "       1.60185103e-02, 1.71754020e-02, 1.67304434e-02, 1.64634689e-02,\n",
      "       1.41496854e-02, 1.52175868e-02, 1.52175868e-02, 1.14799337e-02,\n",
      "       9.70009924e-03, 1.28148096e-02, 1.58405261e-02, 1.59295199e-02,\n",
      "       1.60185103e-02, 1.60185103e-02, 1.61075040e-02, 1.59295199e-02,\n",
      "       1.59295199e-02, 1.53065772e-02, 1.46836344e-02, 1.60185103e-02,\n",
      "       1.60185103e-02, 1.48616185e-02, 1.47726282e-02, 1.47726282e-02,\n",
      "       1.43276696e-02, 1.40606917e-02, 1.40606917e-02, 1.33487586e-02,\n",
      "       1.29037999e-02, 1.24588413e-02, 1.18358986e-02, 1.14799337e-02]), array([0.00000000e+00, 1.77984126e-04, 8.89920632e-05, 1.15689343e-03,\n",
      "       4.18261169e-03, 7.92026477e-03, 9.07715650e-03, 9.52211512e-03,\n",
      "       8.98816613e-03, 8.98816613e-03, 1.14799337e-02, 1.09459813e-02,\n",
      "       1.09459813e-02, 1.15689241e-02, 1.29037999e-02, 1.98451537e-02,\n",
      "       1.81543130e-02, 1.88662461e-02, 1.83322971e-02, 1.71754020e-02,\n",
      "       1.71754020e-02, 1.33487586e-02, 1.49506089e-02, 1.58405261e-02,\n",
      "       1.51285930e-02, 1.36157330e-02, 1.53955675e-02, 1.60185103e-02,\n",
      "       1.71754020e-02, 1.67304434e-02, 1.64634689e-02, 1.41496854e-02,\n",
      "       1.52175868e-02, 1.52175868e-02, 1.14799337e-02, 9.70009924e-03,\n",
      "       1.28148096e-02, 1.58405261e-02, 1.59295199e-02, 1.60185103e-02,\n",
      "       1.60185103e-02, 1.61075040e-02, 1.59295199e-02, 1.59295199e-02,\n",
      "       1.53065772e-02, 1.46836344e-02, 1.60185103e-02, 1.60185103e-02,\n",
      "       1.48616185e-02, 1.47726282e-02, 1.47726282e-02, 1.43276696e-02,\n",
      "       1.40606917e-02, 1.40606917e-02, 1.33487586e-02, 1.29037999e-02,\n",
      "       1.24588413e-02, 1.18358986e-02, 1.14799337e-02, 1.17469082e-02])]\n",
      "\n",
      "[0.011746908208576379, 0.01147993371640154]\n",
      "[array([0.00000000e+00, 0.00000000e+00, 1.77984126e-04, 8.89920632e-05,\n",
      "       1.15689343e-03, 4.18261169e-03, 7.92026477e-03, 9.07715650e-03,\n",
      "       9.52211512e-03, 8.98816613e-03, 8.98816613e-03, 1.14799337e-02,\n",
      "       1.09459813e-02, 1.09459813e-02, 1.15689241e-02, 1.29037999e-02,\n",
      "       1.98451537e-02, 1.81543130e-02, 1.88662461e-02, 1.83322971e-02,\n",
      "       1.71754020e-02, 1.71754020e-02, 1.33487586e-02, 1.49506089e-02,\n",
      "       1.58405261e-02, 1.51285930e-02, 1.36157330e-02, 1.53955675e-02,\n",
      "       1.60185103e-02, 1.71754020e-02, 1.67304434e-02, 1.64634689e-02,\n",
      "       1.41496854e-02, 1.52175868e-02, 1.52175868e-02, 1.14799337e-02,\n",
      "       9.70009924e-03, 1.28148096e-02, 1.58405261e-02, 1.59295199e-02,\n",
      "       1.60185103e-02, 1.60185103e-02, 1.61075040e-02, 1.59295199e-02,\n",
      "       1.59295199e-02, 1.53065772e-02, 1.46836344e-02, 1.60185103e-02,\n",
      "       1.60185103e-02, 1.48616185e-02, 1.47726282e-02, 1.47726282e-02,\n",
      "       1.43276696e-02, 1.40606917e-02, 1.40606917e-02, 1.33487586e-02,\n",
      "       1.29037999e-02, 1.24588413e-02, 1.18358986e-02, 1.14799337e-02]), array([0.00000000e+00, 1.77984126e-04, 8.89920632e-05, 1.15689343e-03,\n",
      "       4.18261169e-03, 7.92026477e-03, 9.07715650e-03, 9.52211512e-03,\n",
      "       8.98816613e-03, 8.98816613e-03, 1.14799337e-02, 1.09459813e-02,\n",
      "       1.09459813e-02, 1.15689241e-02, 1.29037999e-02, 1.98451537e-02,\n",
      "       1.81543130e-02, 1.88662461e-02, 1.83322971e-02, 1.71754020e-02,\n",
      "       1.71754020e-02, 1.33487586e-02, 1.49506089e-02, 1.58405261e-02,\n",
      "       1.51285930e-02, 1.36157330e-02, 1.53955675e-02, 1.60185103e-02,\n",
      "       1.71754020e-02, 1.67304434e-02, 1.64634689e-02, 1.41496854e-02,\n",
      "       1.52175868e-02, 1.52175868e-02, 1.14799337e-02, 9.70009924e-03,\n",
      "       1.28148096e-02, 1.58405261e-02, 1.59295199e-02, 1.60185103e-02,\n",
      "       1.60185103e-02, 1.61075040e-02, 1.59295199e-02, 1.59295199e-02,\n",
      "       1.53065772e-02, 1.46836344e-02, 1.60185103e-02, 1.60185103e-02,\n",
      "       1.48616185e-02, 1.47726282e-02, 1.47726282e-02, 1.43276696e-02,\n",
      "       1.40606917e-02, 1.40606917e-02, 1.33487586e-02, 1.29037999e-02,\n",
      "       1.24588413e-02, 1.18358986e-02, 1.14799337e-02, 1.17469082e-02]), array([1.77984126e-04, 8.89920632e-05, 1.15689343e-03, 4.18261169e-03,\n",
      "       7.92026477e-03, 9.07715650e-03, 9.52211512e-03, 8.98816613e-03,\n",
      "       8.98816613e-03, 1.14799337e-02, 1.09459813e-02, 1.09459813e-02,\n",
      "       1.15689241e-02, 1.29037999e-02, 1.98451537e-02, 1.81543130e-02,\n",
      "       1.88662461e-02, 1.83322971e-02, 1.71754020e-02, 1.71754020e-02,\n",
      "       1.33487586e-02, 1.49506089e-02, 1.58405261e-02, 1.51285930e-02,\n",
      "       1.36157330e-02, 1.53955675e-02, 1.60185103e-02, 1.71754020e-02,\n",
      "       1.67304434e-02, 1.64634689e-02, 1.41496854e-02, 1.52175868e-02,\n",
      "       1.52175868e-02, 1.14799337e-02, 9.70009924e-03, 1.28148096e-02,\n",
      "       1.58405261e-02, 1.59295199e-02, 1.60185103e-02, 1.60185103e-02,\n",
      "       1.61075040e-02, 1.59295199e-02, 1.59295199e-02, 1.53065772e-02,\n",
      "       1.46836344e-02, 1.60185103e-02, 1.60185103e-02, 1.48616185e-02,\n",
      "       1.47726282e-02, 1.47726282e-02, 1.43276696e-02, 1.40606917e-02,\n",
      "       1.40606917e-02, 1.33487586e-02, 1.29037999e-02, 1.24588413e-02,\n",
      "       1.18358986e-02, 1.14799337e-02, 1.17469082e-02, 1.14799337e-02])]\n",
      "\n",
      "[0.011746908208576379, 0.01147993371640154, 0.010679006845112186]\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 60, 50)            10400     \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "3516/3516 [==============================] - 76s 21ms/step - loss: 8.9420e-04\n",
      "Epoch 2/10\n",
      "3516/3516 [==============================] - 75s 21ms/step - loss: 3.7043e-04\n",
      "Epoch 3/10\n",
      "3516/3516 [==============================] - 82s 23ms/step - loss: 3.2463e-04\n",
      "Epoch 4/10\n",
      "3516/3516 [==============================] - 82s 23ms/step - loss: 2.6318e-04\n",
      "Epoch 5/10\n",
      "3516/3516 [==============================] - 69s 20ms/step - loss: 2.3084e-04\n",
      "Epoch 6/10\n",
      "3516/3516 [==============================] - 74s 21ms/step - loss: 1.8335e-04\n",
      "Epoch 7/10\n",
      "3516/3516 [==============================] - 67s 19ms/step - loss: 1.7281e-04\n",
      "Epoch 8/10\n",
      "3516/3516 [==============================] - 68s 19ms/step - loss: 1.4735e-04\n",
      "Epoch 9/10\n",
      "3516/3516 [==============================] - 72s 21ms/step - loss: 1.6020e-04\n",
      "Epoch 10/10\n",
      "3516/3516 [==============================] - 73s 21ms/step - loss: 1.4576e-04\n",
      "Root mean square error in predicted vs actual values  0.257055773297679\n",
      "stock name  PETRONET.NS\n",
      "[array([0.56022263, 0.5466562 , 0.55822246, 0.5717019 , 0.57622399,\n",
      "       0.6164884 , 0.61483606, 0.62561963, 0.63292463, 0.65875292,\n",
      "       0.66092702, 0.65031745, 0.63318546, 0.60935733, 0.60770499,\n",
      "       0.60935733, 0.59187752, 0.59761718, 0.58283329, 0.59057306,\n",
      "       0.59179058, 0.61170537, 0.62388035, 0.62805456, 0.60405249,\n",
      "       0.60848769, 0.59092094, 0.59066006, 0.58065919, 0.57691974,\n",
      "       0.57326724, 0.56561441, 0.5723976 , 0.57004956, 0.5723976 ,\n",
      "       0.56491866, 0.54622138, 0.5489173 , 0.59344292, 0.56083139,\n",
      "       0.57109314, 0.57361506, 0.56526653, 0.5481346 , 0.54917818,\n",
      "       0.55717888, 0.55517872, 0.54839548, 0.5930081 , 0.59709537,\n",
      "       0.59718236, 0.62170624, 0.6356205 , 0.66257936, 0.6825811 ,\n",
      "       0.687712  , 0.69084269, 0.65997044, 0.66953649, 0.66579699])]\n",
      "\n",
      "[0.6632750108519327]\n",
      "[array([0.56022263, 0.5466562 , 0.55822246, 0.5717019 , 0.57622399,\n",
      "       0.6164884 , 0.61483606, 0.62561963, 0.63292463, 0.65875292,\n",
      "       0.66092702, 0.65031745, 0.63318546, 0.60935733, 0.60770499,\n",
      "       0.60935733, 0.59187752, 0.59761718, 0.58283329, 0.59057306,\n",
      "       0.59179058, 0.61170537, 0.62388035, 0.62805456, 0.60405249,\n",
      "       0.60848769, 0.59092094, 0.59066006, 0.58065919, 0.57691974,\n",
      "       0.57326724, 0.56561441, 0.5723976 , 0.57004956, 0.5723976 ,\n",
      "       0.56491866, 0.54622138, 0.5489173 , 0.59344292, 0.56083139,\n",
      "       0.57109314, 0.57361506, 0.56526653, 0.5481346 , 0.54917818,\n",
      "       0.55717888, 0.55517872, 0.54839548, 0.5930081 , 0.59709537,\n",
      "       0.59718236, 0.62170624, 0.6356205 , 0.66257936, 0.6825811 ,\n",
      "       0.687712  , 0.69084269, 0.65997044, 0.66953649, 0.66579699]), array([0.5466562 , 0.55822246, 0.5717019 , 0.57622399, 0.6164884 ,\n",
      "       0.61483606, 0.62561963, 0.63292463, 0.65875292, 0.66092702,\n",
      "       0.65031745, 0.63318546, 0.60935733, 0.60770499, 0.60935733,\n",
      "       0.59187752, 0.59761718, 0.58283329, 0.59057306, 0.59179058,\n",
      "       0.61170537, 0.62388035, 0.62805456, 0.60405249, 0.60848769,\n",
      "       0.59092094, 0.59066006, 0.58065919, 0.57691974, 0.57326724,\n",
      "       0.56561441, 0.5723976 , 0.57004956, 0.5723976 , 0.56491866,\n",
      "       0.54622138, 0.5489173 , 0.59344292, 0.56083139, 0.57109314,\n",
      "       0.57361506, 0.56526653, 0.5481346 , 0.54917818, 0.55717888,\n",
      "       0.55517872, 0.54839548, 0.5930081 , 0.59709537, 0.59718236,\n",
      "       0.62170624, 0.6356205 , 0.66257936, 0.6825811 , 0.687712  ,\n",
      "       0.69084269, 0.65997044, 0.66953649, 0.66579699, 0.66327501])]\n",
      "\n",
      "[0.6632750108519327, 0.6604922026912794]\n",
      "[array([0.56022263, 0.5466562 , 0.55822246, 0.5717019 , 0.57622399,\n",
      "       0.6164884 , 0.61483606, 0.62561963, 0.63292463, 0.65875292,\n",
      "       0.66092702, 0.65031745, 0.63318546, 0.60935733, 0.60770499,\n",
      "       0.60935733, 0.59187752, 0.59761718, 0.58283329, 0.59057306,\n",
      "       0.59179058, 0.61170537, 0.62388035, 0.62805456, 0.60405249,\n",
      "       0.60848769, 0.59092094, 0.59066006, 0.58065919, 0.57691974,\n",
      "       0.57326724, 0.56561441, 0.5723976 , 0.57004956, 0.5723976 ,\n",
      "       0.56491866, 0.54622138, 0.5489173 , 0.59344292, 0.56083139,\n",
      "       0.57109314, 0.57361506, 0.56526653, 0.5481346 , 0.54917818,\n",
      "       0.55717888, 0.55517872, 0.54839548, 0.5930081 , 0.59709537,\n",
      "       0.59718236, 0.62170624, 0.6356205 , 0.66257936, 0.6825811 ,\n",
      "       0.687712  , 0.69084269, 0.65997044, 0.66953649, 0.66579699]), array([0.5466562 , 0.55822246, 0.5717019 , 0.57622399, 0.6164884 ,\n",
      "       0.61483606, 0.62561963, 0.63292463, 0.65875292, 0.66092702,\n",
      "       0.65031745, 0.63318546, 0.60935733, 0.60770499, 0.60935733,\n",
      "       0.59187752, 0.59761718, 0.58283329, 0.59057306, 0.59179058,\n",
      "       0.61170537, 0.62388035, 0.62805456, 0.60405249, 0.60848769,\n",
      "       0.59092094, 0.59066006, 0.58065919, 0.57691974, 0.57326724,\n",
      "       0.56561441, 0.5723976 , 0.57004956, 0.5723976 , 0.56491866,\n",
      "       0.54622138, 0.5489173 , 0.59344292, 0.56083139, 0.57109314,\n",
      "       0.57361506, 0.56526653, 0.5481346 , 0.54917818, 0.55717888,\n",
      "       0.55517872, 0.54839548, 0.5930081 , 0.59709537, 0.59718236,\n",
      "       0.62170624, 0.6356205 , 0.66257936, 0.6825811 , 0.687712  ,\n",
      "       0.69084269, 0.65997044, 0.66953649, 0.66579699, 0.66327501]), array([0.55822246, 0.5717019 , 0.57622399, 0.6164884 , 0.61483606,\n",
      "       0.62561963, 0.63292463, 0.65875292, 0.66092702, 0.65031745,\n",
      "       0.63318546, 0.60935733, 0.60770499, 0.60935733, 0.59187752,\n",
      "       0.59761718, 0.58283329, 0.59057306, 0.59179058, 0.61170537,\n",
      "       0.62388035, 0.62805456, 0.60405249, 0.60848769, 0.59092094,\n",
      "       0.59066006, 0.58065919, 0.57691974, 0.57326724, 0.56561441,\n",
      "       0.5723976 , 0.57004956, 0.5723976 , 0.56491866, 0.54622138,\n",
      "       0.5489173 , 0.59344292, 0.56083139, 0.57109314, 0.57361506,\n",
      "       0.56526653, 0.5481346 , 0.54917818, 0.55717888, 0.55517872,\n",
      "       0.54839548, 0.5930081 , 0.59709537, 0.59718236, 0.62170624,\n",
      "       0.6356205 , 0.66257936, 0.6825811 , 0.687712  , 0.69084269,\n",
      "       0.65997044, 0.66953649, 0.66579699, 0.66327501, 0.6604922 ])]\n",
      "\n",
      "[0.6632750108519327, 0.6604922026912794, 0.6552743577720592]\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 60, 50)            10400     \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 18s 21ms/step - loss: 0.0068\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 0.0026\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 0.0021\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 14s 19ms/step - loss: 0.0017\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 0.0015\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 15s 20ms/step - loss: 0.0011\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 0.0012\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 14s 19ms/step - loss: 0.0011\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 18s 24ms/step - loss: 0.0011\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 18s 24ms/step - loss: 0.0011\n",
      "Root mean square error in predicted vs actual values  4.64528076171875\n",
      "stock name  BANDHANBNK.NS\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "import pandas as pd \n",
    "import pandas_datareader as pdr \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import sequential\n",
    "from keras.layers import Dense , LSTM\n",
    "from keras.models import Sequential\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "import datetime\n",
    "from datetime import  timedelta\n",
    "\n",
    "\n",
    "\n",
    "#'NTPC.NS','HEROMOTOCO.NS','TECHM.NS'\t,'COALINDIA.NS','APOLLOHOSP.NS','ITC.NS','HINDALCO.NS','LTI.NS',\t'INDUSINDBK.NS'\t,'AMARAJABAT.NS',\t'BERGEPAINT.NS'\t,'GUJGASLTD.NS',\t'HDFC.NS'\t,'HDFCAMC.NS'\t,\n",
    "set = [\n",
    "'HINDUNILVR.NS'\t,\n",
    "'IGL.NS'\t,\n",
    "'IRFC.NS'\t,\n",
    "'PETRONET.NS'\t,\n",
    "'BANDHANBNK.NS'\t,\n",
    "]\n",
    "for i in range(len(set)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Get the stock quote\n",
    "    # name should be exact from yahoo finance site\n",
    "    stock_name = set[i]\n",
    "    df = pdr.DataReader(stock_name , data_source='yahoo',start='2000-01-01',end=datetime.datetime.now())\n",
    "\n",
    "    # show the data \n",
    "    df\n",
    "\n",
    "\n",
    "    #df.to_csv('price.csv') to save data as csv\n",
    "\n",
    "    df.shape\n",
    "\n",
    "    # Creating a new df for only close price \n",
    "    #data = df.filter(['Close','High'])           # gives 2 column \n",
    "    data = df.filter(['Close'])                   # gives 1 column\n",
    "    data\n",
    "\n",
    "    # create df to a  num py array         df.values : Only the values in the DataFrame will be returned, the axes labels will be removed.\n",
    "\n",
    "    dataset = data.values\n",
    "    dataset\n",
    "\n",
    "\n",
    "    # Get the no of adta to train the model on say 80%\n",
    "    training_data_len = math.ceil(len(dataset)*0.80)                    #Return the ceiling of x as an Integral.\n",
    "    training_data_len\n",
    "\n",
    "    # scale the data \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(dataset)                        # range [0-1] on numpy array of dataset\n",
    "    scaled_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # create a scaled training data set \n",
    "    train_data = scaled_data[0:training_data_len , : ]                # till row = training data len all column points\n",
    "\n",
    "    # split the data into x_train  , and y_train data sets\n",
    "    x_train = []                                                      # features = independent variables \n",
    "    y_train = []                                                      # lables = output = dependent variables \n",
    "\n",
    "    for i in range(60 , len(train_data)): \n",
    "        x_train.append(train_data[i-60:i , 0])                        # we are going to append 0 to 89th  values of train_data in 0th column\n",
    "        y_train.append(train_data[i , 0])                             # lable/ prediction is 90th data point of 0th column from train_data to y_train\n",
    "\n",
    "        if i <= 62:\n",
    "            print(x_train)\n",
    "            print()\n",
    "            print(y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # convert x_train and y_train to numpy arrays so that array data can be provided to LSTM model\n",
    "    x_train , y_train = np.array(x_train) , np.array(y_train)\n",
    "\n",
    "    # x_train.shape               (2363, 30)   # after appending in every row tere are 30 columns of data \n",
    "\n",
    "    # x_train                                  # is 2d type row  and column data\n",
    "\n",
    "    # reshaping the x_train data set as a LSTM model expects the input to be a three dimentionals array \n",
    "    x_train = np.reshape(x_train ,newshape= (x_train.shape[0] , x_train.shape[1] , 1))\n",
    "    x_train.shape\n",
    "\n",
    "    # Build the LSTM model \n",
    "    model = Sequential()\n",
    "\n",
    "    # add a layer of 50 neuron , there output to be used in next layer thus return seq = true , since first layer thus shape of input neuron   , \n",
    "    # input shape = (time step , features ) = (90 days , 1 ) = (90 , close price)\n",
    "    model.add(LSTM(50, activation ='relu', return_sequences=True, input_shape = (x_train.shape[1],1)))\n",
    "\n",
    "    # add 1 last lstm layer but no lstm further thus return_sequence = False\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "\n",
    "    # adding last dense layer          \n",
    "    model.add(Dense(25))  \n",
    "\n",
    "    # adding last dense layer          \n",
    "    model.add(Dense(1)) \n",
    "\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "\n",
    "    # compile the model \n",
    "    # optimizer is used to minimise the loss fx \n",
    "    # loss fx is used to calculate what was the loss to see how well the model did on traiing \n",
    "\n",
    "    model.compile(optimizer='adam' , loss=\"mean_squared_error\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # train the model\n",
    "    model.fit(x=x_train,y=y_train,batch_size=1,epochs=10)\n",
    "\n",
    "\n",
    "\n",
    "    model.save('{}_keras_model.h5'.format(stock_name))\n",
    "    \n",
    "    # creating the testing data set\n",
    "    # create a new array containing scaled values from index  end of len(train_data) till end of the total data\n",
    "\n",
    "    test_data = scaled_data[training_data_len-60 : , : ]         # all data from 60th to end of data with all column\n",
    "\n",
    "    # creating a dataset x_test and y_test\n",
    "    x_test = []\n",
    "    y_test = dataset[training_data_len : , : ]                          # actual prediction values\n",
    "                                                                        # dataset values are original closing prce and not scaled\n",
    "\n",
    "    for i in range(60 , len(test_data)):\n",
    "        x_test.append(test_data[i-60 : i, 0 ])\n",
    "\n",
    "\n",
    "\n",
    "    # create the data to a numpy array as model need 3d array\n",
    "    x_test = np.array(x_test)\n",
    "\n",
    "    # reshape the data for the model      (newshape =no of rows = x_test.shape[0], timesteps = 60 days = x_test.shape[1] , and 1 )\n",
    "    x_test = np.reshape(x_test , newshape= (x_test.shape[0] , x_test.shape[1] , 1 ))\n",
    "\n",
    "\n",
    "    y_predictions = model.predict(x_test)    # scaled value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # undo scaling\n",
    "                                                               # we want the predictions to be exact same as real lables \n",
    "    y_predictions = scaler.inverse_transform(y_predictions)        # Undo the scaling of X according to feature_range(0-1)\n",
    "                                                               # gaining back the real value\n",
    "\n",
    "    # EVALUATE THE MODEL root mean square error (RMSE)\n",
    "    # its a measure of how good the model predicts the response \n",
    "    # can be compared by std deviation less\n",
    "    # lower value of rmse is better : try diff range of dataset \n",
    "\n",
    "    rmse = np.sqrt(np.mean(y_predictions - y_test)**2)\n",
    "    print('Root mean square error in predicted vs actual values ', rmse)\n",
    "    print(\"stock name \" , stock_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e2be2-a971-4b66-ac4e-ce72ce796652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f9c221-dd0b-4288-b5bd-1f1a7fda390c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
